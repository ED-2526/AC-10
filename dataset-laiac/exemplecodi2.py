import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score

# --- CONFIGURACI√ì ---
DATA_FILE = 'SpotifyFeatures.csv' # Assegura't que el nom √©s correcte

def load_data(filepath):
    """Carrega el dataset i mostra informaci√≥ b√†sica."""
    print(f"üìÇ Carregant dades de: {filepath}...")
    try:
        df = pd.read_csv(filepath)
        print(f"   Shape inicial: {df.shape}")
        return df
    except FileNotFoundError:
        print("‚ùå Error: No s'ha trobat l'arxiu CSV.")
        return None

def exploratory_data_analysis(df):
    """
    Realitza l'An√†lisi Explorat√≤ria (EDA) t√≠pica d'aquest notebook.
    Mostra la matriu de correlaci√≥ (Important per AE).
    """
    print("üìä Generant matriu de correlaci√≥...")
    
    # Seleccionem nom√©s columnes num√®riques per la correlaci√≥
    numeric_df = df.select_dtypes(include=[np.number])
    
    plt.figure(figsize=(12, 10))
    # Calculem la correlaci√≥
    corr_matrix = numeric_df.corr()
    
    # Dibuixem el heatmap
    sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', linewidths=0.5)
    plt.title('Matriu de Correlaci√≥ de les Caracter√≠stiques d\'√Äudio')
    plt.show()

def preprocess_data(df):
    """Neteja i normalitza les dades."""
    print("üßπ Preprocessant les dades...")
    
    # Selecci√≥ de features t√≠piques d'aquest notebook
    features = [
        'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 
        'instrumentalness', 'liveness', 'valence', 'tempo'
    ]
    
    # Filtrar columnes existents
    existing_features = [col for col in features if col in df.columns]
    df_clean = df.dropna(subset=existing_features).reset_index(drop=True)
    X = df_clean[existing_features]
    
    # Escalat (StandardScaler)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    return df_clean, X_scaled

def evaluate_kmeans(X_scaled, k_range=range(2, 11)):
    """
    Avalua K-Means usant el m√®tode de l'Elbow i el Silhouette Score.
    Aix√≤ correspon a la secci√≥ 'Model Evaluation' del teu notebook.
    """
    print("üî¨ Avaluant K-Means (Elbow i Silhouette)...")
    
    sse = []
    silhouette_scores = []
    
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')
        kmeans.fit(X_scaled)
        sse.append(kmeans.inertia_)
        score = silhouette_score(X_scaled, kmeans.labels_)
        silhouette_scores.append(score)
        print(f"   K={k}: Silhouette Score = {score:.4f}")

    # Gr√†fic 1: Elbow
    plt.figure(figsize=(14, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(k_range, sse, marker='o')
    plt.title('M√®tode del Colze (Inertia)')
    plt.xlabel('K')
    plt.ylabel('SSE')
    
    # Gr√†fic 2: Silhouette
    plt.subplot(1, 2, 2)
    plt.plot(k_range, silhouette_scores, marker='o', color='green')
    plt.title('Silhouette Score (M√©s alt √©s millor)')
    plt.xlabel('K')
    plt.ylabel('Score')
    
    plt.tight_layout()
    plt.show()

def run_clustering_models(df, X_scaled):
    """
    Executa els models finals i visualitza amb PCA.
    """
    # Per visualitzar en 2D necessitem PCA
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_scaled)
    
    # --- MODEL 1: K-MEANS (Suposem K=4 o 5 basat en l'an√†lisi previ) ---
    k_final = 5
    print(f"üöÄ Entrenant K-Means final amb K={k_final}...")
    kmeans = KMeans(n_clusters=k_final, random_state=42, n_init='auto')
    clusters_kmeans = kmeans.fit_predict(X_scaled)
    df['cluster_kmeans'] = clusters_kmeans
    
    # --- MODEL 2: DBSCAN ---
    # Nota: DBSCAN √©s sensible als par√†metres. 
    eps_val = 0.5
    min_samples_val = 5
    print(f"üöÄ Entrenant DBSCAN (eps={eps_val}, min_samples={min_samples_val})...")
    dbscan = DBSCAN(eps=eps_val, min_samples=min_samples_val)
    clusters_dbscan = dbscan.fit_predict(X_scaled)
    df['cluster_dbscan'] = clusters_dbscan
    
    # --- VISUALITZACI√ì ---
    plt.figure(figsize=(16, 6))
    
    # Plot K-Means
    plt.subplot(1, 2, 1)
    sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters_kmeans, palette='viridis', s=50)
    plt.title(f'Resultat K-Means (K={k_final})')
    plt.xlabel('PC1')
    plt.ylabel('PC2')
    
    # Plot DBSCAN
    plt.subplot(1, 2, 2)
    sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters_dbscan, palette='plasma', s=50)
    plt.title('Resultat DBSCAN')
    plt.xlabel('PC1')
    plt.ylabel('PC2')
    
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    # Flux principal d'execuci√≥
    df = load_data(DATA_FILE)
    
    if df is not None:
        # 1. EDA
        exploratory_data_analysis(df)
        
        # 2. Preprocessament
        df_clean, X_scaled = preprocess_data(df)
        
        # 3. Avaluaci√≥ de Models (Important per AC)
        evaluate_kmeans(X_scaled, k_range=range(2, 10))
        
        # 4. Execuci√≥ Final i Visualitzaci√≥
        run_clustering_models(df_clean, X_scaled)
        
        print("\n‚úÖ An√†lisi completa finalitzada.")